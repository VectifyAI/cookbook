{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIjn2vW1ooxz"
      },
      "source": [
        "# PageIndex OCR and Tree Generation\n",
        "In this notebook, we will explore how to use the PageIndex OCR to convert a PDF document into a markdown file and get the tree structure of the document.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Install the SDK\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY9af_12oox0",
        "outputId": "833c86ad-e290-4831-cdc3-0f83aae433f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pageindex\n",
            "  Downloading pageindex-0.1.5-py3-none-any.whl.metadata (600 bytes)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from pageindex) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->pageindex) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->pageindex) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->pageindex) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->pageindex) (2025.7.14)\n",
            "Downloading pageindex-0.1.5-py3-none-any.whl (2.9 kB)\n",
            "Installing collected packages: pageindex\n",
            "Successfully installed pageindex-0.1.5\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pageindex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mgLrLd6oox0"
      },
      "source": [
        "## 2. Initialize the Client\n",
        "\n",
        "You can get your API key in the [Dashboard](https://dash.pageindex.ai/api-keys)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vr9JN4Tsoox0"
      },
      "outputs": [],
      "source": [
        "from pageindex import PageIndexClient\n",
        "\n",
        "API_KEY = \"Your API Key\" ## you can get your API key in https://dash.pageindex.ai/api-keys\n",
        "pi_client = PageIndexClient(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWIFjkH2oox0"
      },
      "source": [
        "## 3. Submit a PDF Document for OCR\n",
        "\n",
        "- Use the client to upload a PDF file for OCR processing (currently supports PDF files only).\n",
        "\n",
        "- After submission, you'll receive a `doc_id` that you can use to check status and get OCR results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znRzYxHQoox0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0abacdfd-09b7-43a4-d5fc-92e6877b05bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded file to: ../data/2501.12948.pdf\n",
            "Document submitted. Document ID: pi-cmdxdh35f000x0bpoiaihrsn5\n"
          ]
        }
      ],
      "source": [
        "import requests, os\n",
        "\n",
        "pdf_url = \"https://arxiv.org/pdf/2501.12948.pdf\"\n",
        "pdf_path = os.path.join(\"../data\", pdf_url.split('/')[-1])\n",
        "os.makedirs(os.path.dirname(pdf_path), exist_ok=True)\n",
        "\n",
        "response = requests.get(pdf_url)\n",
        "with open(pdf_path, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(f\"Downloaded file to: {pdf_path}\")\n",
        "result = pi_client.submit_document(pdf_path)\n",
        "doc_id = result[\"doc_id\"]\n",
        "print(f\"Document submitted. Document ID: {doc_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYyFY2aXoox0"
      },
      "source": [
        "## 4. Get Markdown Results\n",
        "\n",
        "- OCR processing may take anywhere from a few seconds (for small files) to several minutes (for larger files)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "E5NFI1XRoox1",
        "outputId": "0ea5804d-e6a2-489e-e344-c9a47f0e95c7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### 1.1. Contributions\n\n#### Post-Training: Large-Scale Reinforcement Learning on the Base Model\n\n- We directly apply RL to the base model without relying on supervised fine-tuning (SFT) as a preliminary step. This approach allows the model to explore chain-of-thought (CoT) for solving complex problems, resulting in the development of DeepSeek-R1-Zero. DeepSeek-R1-Zero demonstrates capabilities such as self-verification, reflection, and generating long CoTs, marking a significant milestone for the research community. Notably, it is the first open research to validate that reasoning capabilities of LLMs can be incentivized purely through RL, without the need for SFT. This breakthrough paves the way for future advancements in this area.\n- We introduce our pipeline to develop DeepSeek-R1. The pipeline incorporates two RL stages aimed at discovering improved reasoning patterns and aligning with human preferences, as well as two SFT stages that serve as the seed for the model's reasoning and non-reasoning capabilities. We believe the pipeline will benefit the industry by creating better models.\n\n\n#### Distillation: Smaller Models Can Be Powerful Too\n\n- We demonstrate that the reasoning patterns of larger models can be distilled into smaller models, resulting in better performance compared to the reasoning patterns discovered through RL on small models. The open source DeepSeek-R1, as well as its API, will benefit the research community to distill better smaller models in the future.\n- Using the reasoning data generated by DeepSeek-R1, we fine-tuned several dense models that are widely used in the research community. The evaluation results demonstrate that the distilled smaller dense models perform exceptionally well on benchmarks. DeepSeek-R1-Distill-Qwen-7B achieves 55.5\\% on AIME 2024, surpassing QwQ-32B-Preview. Additionally, DeepSeek-R1-Distill-Qwen-32B scores 72.6\\% on AIME 2024, 94.3\\% on MATH-500, and $57.2 \\%$ on LiveCodeBench. These results significantly outperform previous opensource models and are comparable to o1-mini. We open-source distilled 1.5B, 7B, 8B, 14B, 32B, and 70B checkpoints based on Qwen2.5 and Llama3 series to the community.\n\n\n### 1.2. Summary of Evaluation Results\n\n- Reasoning tasks: (1) DeepSeek-R1 achieves a score of 79.8\\% Pass@1 on AIME 2024, slightly surpassing OpenAI-o1-1217. On MATH-500, it attains an impressive score of $97.3 \\%$, performing on par with OpenAI-o1-1217 and significantly outperforming other models. (2) On coding-related tasks, DeepSeek-R1 demonstrates expert level in code competition tasks, as it achieves 2,029 Elo rating on Codeforces outperforming $96.3 \\%$ human participants in the competition. For engineering-related tasks, DeepSeek-R1 performs slightly better than DeepSeek-V3, which could help developers in real world tasks.\n- Knowledge: On benchmarks such as MMLU, MMLU-Pro, and GPQA Diamond, DeepSeekR1 achieves outstanding results, significantly outperforming DeepSeek-V3 with scores of $90.8 \\%$ on MMLU, $84.0 \\%$ on MMLU-Pro, and $71.5 \\%$ on GPQA Diamond. While its performance is slightly below that of OpenAI-o1-1217 on these benchmarks, DeepSeek-R1 surpasses other closed-source models, demonstrating its competitive edge in educational tasks. On the factual benchmark SimpleQA, DeepSeek-R1 outperforms DeepSeek-V3, demonstrating its capability in handling fact-based queries. A similar trend is observed where OpenAI-o1 surpasses 40 on this benchmark."
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "ocr_result = pi_client.get_ocr(doc_id)\n",
        "\n",
        "if ocr_result.get(\"status\") == \"completed\":\n",
        "  markdown_text=ocr_result[\"result\"][3][\"markdown\"]\n",
        "  display(Markdown(markdown_text))\n",
        "else:\n",
        "    print(\"Processing...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBgnTpNJoox1"
      },
      "source": [
        "## 5. Get the PageIndex Tree Structure\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2sTDTFhE7M4",
        "outputId": "647c4302-6a7e-4be0-f56c-6bf32794d7d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Raw Tree Structure without text fields\n",
            "\n",
            "[{'title': 'DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via '\n",
            "           'Reinforcement Learning',\n",
            "  'node_id': '0000',\n",
            "  'page_index': 1,\n",
            "  'nodes': [{'title': 'Abstract', 'node_id': '0001', 'page_index': 1},\n",
            "            {'title': 'Contents', 'node_id': '0002', 'page_index': 2},\n",
            "            {'title': '1. Introduction',\n",
            "             'node_id': '0003',\n",
            "             'page_index': 3,\n",
            "             'nodes': [{'title': '1.1. Contributions',\n",
            "                        'node_id': '0004',\n",
            "                        'page_index': 4,\n",
            "                        'nodes': [{'title': 'Post-Training: Large-Scale '\n",
            "                                            'Reinforcement Learning on the '\n",
            "                                            'Base Model',\n",
            "                                   'node_id': '0005',\n",
            "                                   'page_index': 4},\n",
            "                                  {'title': 'Distillation: Smaller Models Can '\n",
            "                                            'Be Powerful Too',\n",
            "                                   'node_id': '0006',\n",
            "                                   'page_index': 4}]},\n",
            "                       {'title': '1.2. Summary of Evaluation Results',\n",
            "                        'node_id': '0007',\n",
            "                        'page_index': 4}]},\n",
            "            {'title': '2. Approach',\n",
            "             'node_id': '0008',\n",
            "             'page_index': 5,\n",
            "             'nodes': [{'title': '2.1. Overview',\n",
            "                        'node_id': '0009',\n",
            "                        'page_index': 5},\n",
            "                       {'title': '2.2. DeepSeek-R1-Zero: Reinforcement '\n",
            "                                 'Learning on the Base Model',\n",
            "                        'node_id': '0010',\n",
            "                        'page_index': 5,\n",
            "                        'nodes': [{'title': '2.2.1. Reinforcement Learning '\n",
            "                                            'Algorithm',\n",
            "                                   'node_id': '0011',\n",
            "                                   'page_index': 5},\n",
            "                                  {'title': '2.2.2. Reward Modeling',\n",
            "                                   'node_id': '0012',\n",
            "                                   'page_index': 6},\n",
            "                                  {'title': '2.2.3. Training Template',\n",
            "                                   'node_id': '0013',\n",
            "                                   'page_index': 6}]},\n",
            "                       {'title': '2.3. DeepSeek-R1: Reinforcement Learning '\n",
            "                                 'with Cold Start',\n",
            "                        'node_id': '0014',\n",
            "                        'page_index': 9,\n",
            "                        'nodes': [{'title': '2.3.1. Cold Start',\n",
            "                                   'node_id': '0015',\n",
            "                                   'page_index': 9},\n",
            "                                  {'title': '2.3.2. Reasoning-oriented '\n",
            "                                            'Reinforcement Learning',\n",
            "                                   'node_id': '0016',\n",
            "                                   'page_index': 10},\n",
            "                                  {'title': '2.3.3. Rejection Sampling and '\n",
            "                                            'Supervised Fine-Tuning',\n",
            "                                   'node_id': '0017',\n",
            "                                   'page_index': 10},\n",
            "                                  {'title': '2.3.4. Reinforcement Learning for '\n",
            "                                            'all Scenarios',\n",
            "                                   'node_id': '0018',\n",
            "                                   'page_index': 11}]},\n",
            "                       {'title': '2.4. Distillation: Empower Small Models with '\n",
            "                                 'Reasoning Capability',\n",
            "                        'node_id': '0019',\n",
            "                        'page_index': 11}]},\n",
            "            {'title': '3. Experiment',\n",
            "             'node_id': '0020',\n",
            "             'page_index': 11,\n",
            "             'nodes': [{'title': '3.1. DeepSeek-R1 Evaluation',\n",
            "                        'node_id': '0021',\n",
            "                        'page_index': 13},\n",
            "                       {'title': '3.2. Distilled Model Evaluation',\n",
            "                        'node_id': '0022',\n",
            "                        'page_index': 14}]},\n",
            "            {'title': '4. Discussion',\n",
            "             'node_id': '0023',\n",
            "             'page_index': 14,\n",
            "             'nodes': [{'title': '4.1. Distillation v.s. Reinforcement '\n",
            "                                 'Learning',\n",
            "                        'node_id': '0024',\n",
            "                        'page_index': 14},\n",
            "                       {'title': '4.2. Unsuccessful Attempts',\n",
            "                        'node_id': '0025',\n",
            "                        'page_index': 15}]},\n",
            "            {'title': '5. Conclusion, Limitations, and Future Work',\n",
            "             'node_id': '0026',\n",
            "             'page_index': 16},\n",
            "            {'title': 'References', 'node_id': '0027', 'page_index': 17},\n",
            "            {'title': 'Appendix', 'node_id': '0028', 'page_index': 20},\n",
            "            {'title': 'A. Contributions and Acknowledgments',\n",
            "             'node_id': '0029',\n",
            "             'page_index': 20,\n",
            "             'nodes': [{'title': 'Core Contributors',\n",
            "                        'node_id': '0030',\n",
            "                        'page_index': 20},\n",
            "                       {'title': 'Contributors',\n",
            "                        'node_id': '0031',\n",
            "                        'page_index': 20}]}]}]\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "def remove_text_fields(data):\n",
        "    if isinstance(data, dict):\n",
        "        return {k: remove_text_fields(v) for k, v in data.items() if k != 'text'}\n",
        "    elif isinstance(data, list):\n",
        "        return [remove_text_fields(item) for item in data]\n",
        "    return data\n",
        "\n",
        "tree_result = pi_client.get_tree(doc_id)\n",
        "print(\"\\n Raw Tree Structure without text fields\\n\")\n",
        "pprint(remove_text_fields(tree_result.get(\"result\")),sort_dicts=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Print A Simplified Tree Structure"
      ],
      "metadata": {
        "id": "lPBYZk5yIkkF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwR0ooMZoox1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b37fac1e-5435-484d-e1cf-1836417be63d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning\n",
            "  - Abstract\n",
            "  - Contents\n",
            "  - 1. Introduction\n",
            "    - 1.1. Contributions\n",
            "      - Post-Training: Large-Scale Reinforcement Learning on the Base Model\n",
            "      - Distillation: Smaller Models Can Be Powerful Too\n",
            "    - 1.2. Summary of Evaluation Results\n",
            "  - 2. Approach\n",
            "    - 2.1. Overview\n",
            "    - 2.2. DeepSeek-R1-Zero: Reinforcement Learning on the Base Model\n",
            "      - 2.2.1. Reinforcement Learning Algorithm\n",
            "      - 2.2.2. Reward Modeling\n",
            "      - 2.2.3. Training Template\n",
            "    - 2.3. DeepSeek-R1: Reinforcement Learning with Cold Start\n",
            "      - 2.3.1. Cold Start\n",
            "      - 2.3.2. Reasoning-oriented Reinforcement Learning\n",
            "      - 2.3.3. Rejection Sampling and Supervised Fine-Tuning\n",
            "      - 2.3.4. Reinforcement Learning for all Scenarios\n",
            "    - 2.4. Distillation: Empower Small Models with Reasoning Capability\n",
            "  - 3. Experiment\n",
            "    - 3.1. DeepSeek-R1 Evaluation\n",
            "    - 3.2. Distilled Model Evaluation\n",
            "  - 4. Discussion\n",
            "    - 4.1. Distillation v.s. Reinforcement Learning\n",
            "    - 4.2. Unsuccessful Attempts\n",
            "  - 5. Conclusion, Limitations, and Future Work\n",
            "  - References\n",
            "  - Appendix\n",
            "  - A. Contributions and Acknowledgments\n",
            "    - Core Contributors\n",
            "    - Contributors\n"
          ]
        }
      ],
      "source": [
        "def print_toc_from_json(data, indent_size=2):\n",
        "    def print_node(node, level=0):\n",
        "        if isinstance(node, dict):\n",
        "            if 'title' in node:\n",
        "                indent = ' ' * (indent_size * level)\n",
        "                print(f\"{indent}- {node['title']}\")\n",
        "            if 'nodes' in node:\n",
        "                for child in node['nodes']:\n",
        "                    print_node(child, level + 1)\n",
        "        elif isinstance(node, list):\n",
        "            for item in node:\n",
        "                print_node(item, level)\n",
        "    print_node(data)\n",
        "\n",
        "\n",
        "print_toc_from_json(tree_result.get(\"result\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QAzzxjooox1"
      },
      "source": [
        "---\n",
        "# Get Started with the PageIndex OCR API\n",
        "- üîë [Get API Key](https://dash.pageindex.ai/api-keys)\n",
        "- üìñ [SDK Reference](https://pageindex.ai/ocr/sdk)\n",
        "- ü§ù [Join the PageIndex Discord](https://discord.gg/VuXuf29EUj)\n",
        "- üì® [Contact Support](https://ii2abc2jejf.typeform.com/to/meB40zV0)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}