{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIjn2vW1ooxz"
   },
   "source": [
    "## 1Ô∏è‚É£ Install the SDK\n",
    "\n",
    "Run the cell below to install the PageIndex OCR SDK. This only needs to be done once in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zY9af_12oox0",
    "outputId": "67c620b7-e420-48b4-9fd8-948796048d24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pageindex in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.10/site-packages (0.1.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.10/site-packages (from pageindex) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->pageindex) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->pageindex) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->pageindex) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->pageindex) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pageindex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mgLrLd6oox0"
   },
   "source": [
    "## 2Ô∏è‚É£ Initialize the Client\n",
    "\n",
    "Import the PageIndex client class and authenticate using your API key. Be sure to keep your API key secret and never share it publicly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vr9JN4Tsoox0"
   },
   "outputs": [],
   "source": [
    "from pageindex import PageIndexClient\n",
    "\n",
    "# Paste your API key here, you can get the api key from https://dash.pageindex.ai/api-keys\n",
    "API_KEY = \"YOUR_API_KEY\"  \n",
    "pi_client = PageIndexClient(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWIFjkH2oox0"
   },
   "source": [
    "## 3Ô∏è‚É£ Submit a PDF Document for OCR\n",
    "\n",
    "Use the client to upload a PDF file for OCR processing (currently supports PDF files only).\n",
    "\n",
    "After submission, you'll receive a `doc_id` that you can use to check status and get OCR results.\n",
    "\n",
    "> Replace the file path below with your own PDF file if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "znRzYxHQoox0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file to: ../data/2501.12948.pdf\n",
      "Document submitted. Document ID: pi-cmdx5og74000a08pobe43rdjf\n"
     ]
    }
   ],
   "source": [
    "import requests, os\n",
    "\n",
    "pdf_url = \"https://arxiv.org/pdf/2501.12948.pdf\"\n",
    "pdf_path = os.path.join(\"../data\", pdf_url.split('/')[-1])\n",
    "os.makedirs(os.path.dirname(pdf_path), exist_ok=True)\n",
    "\n",
    "response = requests.get(pdf_url)\n",
    "with open(pdf_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "print(f\"Downloaded file to: {pdf_path}\")\n",
    "result = pi_client.submit_document(pdf_path)\n",
    "doc_id = result[\"doc_id\"]\n",
    "print(f\"Document submitted. Document ID: {doc_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYyFY2aXoox0"
   },
   "source": [
    "## 4Ô∏è‚É£ Check Status and Get OCR Results\n",
    "\n",
    "OCR processing may take anywhere from a few seconds (for small files) to several minutes (for larger files).\n",
    "\n",
    "This code polls the service every 3 seconds, for up to 5 minutes. Once finished, it previews the extracted text from the first page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "E5NFI1XRoox1",
    "outputId": "c03cbf31-d4c3-4d08-97fb-847587cdb371"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR Results ready!\n",
      "Page 1 (partial content):\n",
      "\n",
      "# DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning\n",
      "\n",
      "DeepSeek-AI<br>research@deepseek.com\n",
      "\n",
      "\n",
      "## Abstract\n",
      "\n",
      "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeekR1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Simple polling\n",
    "for attempt in range(60):  # Try up to 300s (100 x 3s)\n",
    "    ocr_result = pi_client.get_ocr(doc_id)\n",
    "    if ocr_result[\"status\"] == \"completed\":\n",
    "        print(\"OCR Results ready!\")\n",
    "        break\n",
    "    elif ocr_result[\"status\"] == \"failed\":\n",
    "        print(\"OCR failed.\")\n",
    "        break\n",
    "    time.sleep(3)\n",
    "else:\n",
    "    print(\"Still processing after 10 minutes. Try again later.\")\n",
    "\n",
    "# Preview the first page's markdown\n",
    "if ocr_result.get(\"status\") == \"completed\":\n",
    "    if ocr_result[\"result\"]:\n",
    "        first_page = ocr_result[\"result\"][0]\n",
    "        print(f\"Page {first_page['page_index']} (partial content):\\n\")\n",
    "        print(first_page[\"markdown\"][:1000])  # Print first 1000 chars\n",
    "    else:\n",
    "        print(\"No pages found in OCR result.\")\n",
    "else:\n",
    "    print(\"OCR not completed yet. Try again later.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_toc_from_json(json_data, indent_size=2):\n",
    "    headings = []\n",
    "    \n",
    "    if 'pages' in json_data:\n",
    "        for page in json_data['pages']:\n",
    "            if 'markdown' in page:\n",
    "                headings.extend(_extract_headings_from_markdown(page['markdown'], page.get('page_index', 0)))\n",
    "    else:\n",
    "        for item in json_data:\n",
    "            if 'nodes' in item:\n",
    "                for node in item['nodes']:\n",
    "                    if 'text' in node:\n",
    "                        headings.extend(_extract_headings_from_markdown(node['text'], node.get('page_index', 0)))\n",
    "    \n",
    "    headings.sort(key=lambda x: (x[2], x[0]))\n",
    "    \n",
    "    toc_lines = []\n",
    "    for level, title, page_index in headings:\n",
    "        indent = '  ' * (level - 1)\n",
    "        toc_lines.append(f\"{indent}- {title}\")\n",
    "    \n",
    "    return '\\n'.join(toc_lines)\n",
    "\n",
    "def _extract_headings_from_markdown(markdown_content, page_index=0):\n",
    "    import re\n",
    "    headings = []\n",
    "    heading_pattern = r'^(#{1,6})\\s+(.+)$'\n",
    "    \n",
    "    for line in markdown_content.split('\\n'):\n",
    "        match = re.match(heading_pattern, line.strip())\n",
    "        if match:\n",
    "            level = len(match.group(1))\n",
    "            title = re.sub(r'\\s+', ' ', match.group(2).strip())\n",
    "            if title:\n",
    "                headings.append((level, title, page_index))\n",
    "    \n",
    "    return headings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBgnTpNJoox1"
   },
   "source": [
    "## 5Ô∏è‚É£ Get the Document Tree Structure\n",
    "\n",
    "You can also get the document's PageIndex tree structure using the method below. If the tree is not ready yet, try again later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "NwR0ooMZoox1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document tree structure loaded!\n",
      "\n",
      "## Table of Contents\n",
      "\n",
      "  - Abstract\n",
      "  - Contents\n",
      "  - 1. Introduction\n",
      "  - 2. Approach\n",
      "  - 3. Experiment\n",
      "  - 4. Discussion\n",
      "  - 5. Conclusion, Limitations, and Future Work\n",
      "  - References\n",
      "  - Appendix\n",
      "  - A. Contributions and Acknowledgments\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def remove_text_fields(data):\n",
    "    if isinstance(data, dict):\n",
    "        return {k: remove_text_fields(v) for k, v in data.items() if k != 'text'}\n",
    "    elif isinstance(data, list):\n",
    "        return [remove_text_fields(item) for item in data]\n",
    "    return data\n",
    "\n",
    "tree_result = pi_client.get_tree(doc_id)\n",
    "if tree_result.get(\"status\") == \"completed\":\n",
    "    print(\"Document tree structure loaded!\")\n",
    "    toc = extract_toc_from_json(tree_result.get(\"result\"))\n",
    "    print(\"\\n## Table of Contents\\n\")\n",
    "    print(toc)\n",
    "else:\n",
    "    print(f\"Tree status: {tree_result.get('status')}. Try again later if still processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document tree structure loaded!\n",
      "\n",
      "## Tree Structure (drop text fields)\n",
      "\n",
      "[{'node_id': '0000',\n",
      "  'nodes': [{'node_id': '0001', 'page_index': 1, 'title': 'Abstract'},\n",
      "            {'node_id': '0002', 'page_index': 2, 'title': 'Contents'},\n",
      "            {'node_id': '0003',\n",
      "             'nodes': [{'node_id': '0004',\n",
      "                        'page_index': 4,\n",
      "                        'title': '1.1. Contributions'},\n",
      "                       {'node_id': '0005',\n",
      "                        'page_index': 4,\n",
      "                        'title': '1.2. Summary of Evaluation Results'}],\n",
      "             'page_index': 3,\n",
      "             'title': '1. Introduction'},\n",
      "            {'node_id': '0006',\n",
      "             'nodes': [{'node_id': '0007',\n",
      "                        'page_index': 5,\n",
      "                        'title': '2.1. Overview'},\n",
      "                       {'node_id': '0008',\n",
      "                        'nodes': [{'node_id': '0009',\n",
      "                                   'page_index': 5,\n",
      "                                   'title': '2.2.1. Reinforcement Learning '\n",
      "                                            'Algorithm'},\n",
      "                                  {'node_id': '0010',\n",
      "                                   'page_index': 6,\n",
      "                                   'title': '2.2.2. Reward Modeling'},\n",
      "                                  {'node_id': '0011',\n",
      "                                   'page_index': 6,\n",
      "                                   'title': '2.2.3. Training Template'},\n",
      "                                  {'node_id': '0012',\n",
      "                                   'page_index': 6,\n",
      "                                   'title': '2.2.4. Performance, '\n",
      "                                            'Self-evolution Process and Aha '\n",
      "                                            'Moment of DeepSeek-R1-Zero'}],\n",
      "                        'page_index': 5,\n",
      "                        'title': '2.2. DeepSeek-R1-Zero: Reinforcement '\n",
      "                                 'Learning on the Base Model'},\n",
      "                       {'node_id': '0013',\n",
      "                        'nodes': [{'node_id': '0014',\n",
      "                                   'page_index': 9,\n",
      "                                   'title': '2.3.1. Cold Start'},\n",
      "                                  {'node_id': '0015',\n",
      "                                   'page_index': 10,\n",
      "                                   'title': '2.3.2. Reasoning-oriented '\n",
      "                                            'Reinforcement Learning'},\n",
      "                                  {'node_id': '0016',\n",
      "                                   'page_index': 10,\n",
      "                                   'title': '2.3.3. Rejection Sampling and '\n",
      "                                            'Supervised Fine-Tuning'},\n",
      "                                  {'node_id': '0017',\n",
      "                                   'page_index': 11,\n",
      "                                   'title': '2.3.4. Reinforcement Learning for '\n",
      "                                            'all Scenarios'}],\n",
      "                        'page_index': 9,\n",
      "                        'title': '2.3. DeepSeek-R1: Reinforcement Learning '\n",
      "                                 'with Cold Start'},\n",
      "                       {'node_id': '0018',\n",
      "                        'page_index': 11,\n",
      "                        'title': '2.4. Distillation: Empower Small Models with '\n",
      "                                 'Reasoning Capability'}],\n",
      "             'page_index': 5,\n",
      "             'title': '2. Approach'},\n",
      "            {'node_id': '0019',\n",
      "             'nodes': [{'node_id': '0020',\n",
      "                        'page_index': 13,\n",
      "                        'title': '3.1. DeepSeek-R1 Evaluation'},\n",
      "                       {'node_id': '0021',\n",
      "                        'page_index': 14,\n",
      "                        'title': '3.2. Distilled Model Evaluation'}],\n",
      "             'page_index': 11,\n",
      "             'title': '3. Experiment'},\n",
      "            {'node_id': '0022',\n",
      "             'nodes': [{'node_id': '0023',\n",
      "                        'page_index': 14,\n",
      "                        'title': '4.1. Distillation v.s. Reinforcement '\n",
      "                                 'Learning'},\n",
      "                       {'node_id': '0024',\n",
      "                        'page_index': 15,\n",
      "                        'title': '4.2. Unsuccessful Attempts'}],\n",
      "             'page_index': 14,\n",
      "             'title': '4. Discussion'},\n",
      "            {'node_id': '0025',\n",
      "             'page_index': 16,\n",
      "             'title': '5. Conclusion, Limitations, and Future Work'},\n",
      "            {'node_id': '0026', 'page_index': 17, 'title': 'References'},\n",
      "            {'node_id': '0027', 'page_index': 20, 'title': 'Appendix'},\n",
      "            {'node_id': '0028',\n",
      "             'nodes': [{'node_id': '0029',\n",
      "                        'page_index': 20,\n",
      "                        'title': 'Core Contributors'},\n",
      "                       {'node_id': '0030',\n",
      "                        'page_index': 20,\n",
      "                        'title': 'Contributors'}],\n",
      "             'page_index': 20,\n",
      "             'title': 'A. Contributions and Acknowledgments'}],\n",
      "  'page_index': 1,\n",
      "  'title': 'DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via '\n",
      "           'Reinforcement Learning'}]\n"
     ]
    }
   ],
   "source": [
    "# print the tree structure\n",
    "if tree_result.get(\"status\") == \"completed\":\n",
    "    print(\"Document tree structure loaded!\")\n",
    "    toc = extract_toc_from_json(tree_result.get(\"result\"))\n",
    "    \n",
    "    print(\"\\n## Tree Structure (drop text fields)\\n\")\n",
    "    pprint(remove_text_fields(tree_result.get(\"result\")))\n",
    "else:\n",
    "    print(f\"Tree status: {tree_result.get('status')}. Try again later if still processing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRmOOrTBoox1"
   },
   "source": [
    "## 6Ô∏è‚É£ Delete the Document (Cleanup)\n",
    "\n",
    "If you do not need the document any more, you can delete it by running the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbSbEwWUoox1"
   },
   "outputs": [],
   "source": [
    "pi_client.delete_document(doc_id)\n",
    "print(\"Document deleted successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QAzzxjooox1"
   },
   "source": [
    "---\n",
    "\n",
    "# üí¨ Notes & Support\n",
    "\n",
    "- Only **PDF files** are supported at this time.\n",
    "- If you have any questions or need help:\n",
    "    - ü§ù [Join the PageIndex Discord](https://discord.gg/VuXuf29EUj)\n",
    "    - üì® [Contact support via Typeform](https://ii2abc2jejf.typeform.com/to/meB40zV0)\n",
    "\n",
    "---\n",
    "\n",
    "### Full SDK Reference  \n",
    "See: [PageIndex OCR SDK Reference](https://pageindex.ai/ocr/sdk) for advanced usage and all available parameters."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
